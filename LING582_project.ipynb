{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from transformers import DistilBertTokenizer\n",
    "import torch\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"train.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = {'am', 'she', \"it's\", 'herself', 'hasn', 'll', 'they', 'do', 'he', \n",
    "              'before', 'where', 'its', 'this', 'can', 'them', 'but', 'these', 'so', 'after', \n",
    "              'couldn', 'himself', 'has', 'once', 'had', 'were', 'by', 'just', 'if', \n",
    "              'of',  'needn', 'here', 'be', 'there',  'didn', 'more', 'on', \n",
    "              'your', 'again',  'will', 'yourselves', 'should', \n",
    "              'his', 'their', 'aren', \"haven't\", 'off', \"you'll\", 'as', 'we', 'few', 'been', 'doing', 'own', \n",
    "              'me', 'between', 'through', 'when', 'down', 'you', 'does', 'because', 'for', 'him', 'the',\n",
    "              \"don't\", 'very', 'an', 'ours', 'at', 'hers', 'is', 'have', 'about', 'themselves', \n",
    "              'any', 'from', 'against', 'i', 'to', 'how', 'it', 'yours', 'theirs', 'not', 'my', \n",
    "              'with', 'in', 'up', 'a', 'what', \"didn't\", 'that',  'ourselves', 'whom', 'during', 'same', \n",
    "              'other', 'and', 'while', 'don', 'all', 'o', 'those', 'into', 'under', 'now', 'too', 'further', \n",
    "              'then', 'itself', 'having', 'who', 'isn', 'most', 'her', \n",
    "              'or', 'did', 'each', 'why', 'above', 'was', 'than', 'are', 'which', 't', 'yourself', 'myself', \n",
    "              'our', 'some', 'out', 'only', 'ma', 'no'}\n",
    "\n",
    "def preprocess(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    words = [word for word in words if word.isalnum()]\n",
    "\n",
    "    # Remove Stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "def safe_preprocess(text):\n",
    "    try:\n",
    "        return preprocess(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with text: {text}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return text  # or return an empty string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TEXT'] = data['TEXT'].apply(safe_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the TEXT column\n",
    "split_data = data['TEXT'].str.split(r'\\[SNIPPET\\]', n=1, expand=True)\n",
    "\n",
    "# If the split results in only one column, fill the second column with NaN\n",
    "split_data[1] = split_data.get(1, None)\n",
    "\n",
    "# Assign the split data to the original dataframe\n",
    "data[['SPAN_1', 'SPAN_2']] = split_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove annoying strings with hashmarks in them (this is easier than figuring out where they come from)\n",
    "def rm_hash(list_of_tokens):\n",
    "\n",
    "    hash = re.compile(r\"(#+)\")\n",
    "    \n",
    "    return [token for token in list_of_tokens if not re.match(hash, token)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idea', 'space', 'traveler', 'visiting', 'earth', 'learn', 'new', 'dance', 'fantastic', 'idea', 'being', 'wayne', 'turned', 'face', 'door', 'shouted', 'hey', 'dance', 'want', 'u', 'teach', 'dance', 'called', 'high', 'dragon', 'bump', 'muffled', 'metallic', 'voice', 'side', 'said', 'nod', 'dan', 'bump', 'hug', 'qui', 'wayne', 'shrugged', 'grinned', 'weakly', 's', 'said', 'earth', 'blasted', 'away', 'destroyed', 'ci', 'ship', 'therefore', 'well', 'therefore', 'first', 'place', 'actually', 'said', 'rid', 'earth']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TOKENIZED_SPAN_1'] = data['SPAN_1'].apply(lambda x: rm_hash(tokenizer.tokenize(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [idea, space, traveler, visiting, earth, learn...\n",
       "1    [raised, dignity, god, accidental, death, caus...\n",
       "2    [got, one, right, thought, drop, over, sort, b...\n",
       "3    [want, sign, paper, joshua, lee, gorman, held,...\n",
       "4    [reason, love, instinct, different, men, earth...\n",
       "5    [inc, word, all, specifically, charles, course...\n",
       "6    [must, something, left, at, lance, shot, u, lo...\n",
       "7    [tell, run, thing, get, want, reached, slowly,...\n",
       "8    [happy, nora, merry, always, kind, home, nothi...\n",
       "9    [spoke, softly, came, room, would, impossible,...\n",
       "Name: TOKENIZED_SPAN_1, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TOKENIZED_SPAN_1'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>SPAN_1</th>\n",
       "      <th>SPAN_2</th>\n",
       "      <th>TOKENIZED_SPAN_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>idea space traveler visiting earth learn new d...</td>\n",
       "      <td>0</td>\n",
       "      <td>idea space traveler visiting earth learn new d...</td>\n",
       "      <td>None</td>\n",
       "      <td>[idea, space, traveler, visiting, earth, learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>raised dignity godhead accidental death causin...</td>\n",
       "      <td>0</td>\n",
       "      <td>raised dignity godhead accidental death causin...</td>\n",
       "      <td>None</td>\n",
       "      <td>[raised, dignity, god, accidental, death, caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>got one right thought drop over sort break ice...</td>\n",
       "      <td>1</td>\n",
       "      <td>got one right thought drop over sort break ice...</td>\n",
       "      <td>None</td>\n",
       "      <td>[got, one, right, thought, drop, over, sort, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>want sign paper joshua lee gorman held pen pus...</td>\n",
       "      <td>1</td>\n",
       "      <td>want sign paper joshua lee gorman held pen pus...</td>\n",
       "      <td>None</td>\n",
       "      <td>[want, sign, paper, joshua, lee, gorman, held,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>reason love instinct different men earth born ...</td>\n",
       "      <td>1</td>\n",
       "      <td>reason love instinct different men earth born ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[reason, love, instinct, different, men, earth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>incoherent word alluded specifically charles c...</td>\n",
       "      <td>1</td>\n",
       "      <td>incoherent word alluded specifically charles c...</td>\n",
       "      <td>None</td>\n",
       "      <td>[inc, word, all, specifically, charles, course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>must something left atlatl lance shot u looked...</td>\n",
       "      <td>0</td>\n",
       "      <td>must something left atlatl lance shot u looked...</td>\n",
       "      <td>None</td>\n",
       "      <td>[must, something, left, at, lance, shot, u, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>tell run thing get want reached slowly forward...</td>\n",
       "      <td>0</td>\n",
       "      <td>tell run thing get want reached slowly forward...</td>\n",
       "      <td>None</td>\n",
       "      <td>[tell, run, thing, get, want, reached, slowly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>happy nora merry always kind home nothing play...</td>\n",
       "      <td>0</td>\n",
       "      <td>happy nora merry always kind home nothing play...</td>\n",
       "      <td>None</td>\n",
       "      <td>[happy, nora, merry, always, kind, home, nothi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>spoke softly came room would impossible buy pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>spoke softly came room would impossible buy pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>[spoke, softly, came, room, would, impossible,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               TEXT  LABEL  \\\n",
       "0   0  idea space traveler visiting earth learn new d...      0   \n",
       "1   1  raised dignity godhead accidental death causin...      0   \n",
       "2   2  got one right thought drop over sort break ice...      1   \n",
       "3   3  want sign paper joshua lee gorman held pen pus...      1   \n",
       "4   4  reason love instinct different men earth born ...      1   \n",
       "5   5  incoherent word alluded specifically charles c...      1   \n",
       "6   6  must something left atlatl lance shot u looked...      0   \n",
       "7   7  tell run thing get want reached slowly forward...      0   \n",
       "8   8  happy nora merry always kind home nothing play...      0   \n",
       "9   9  spoke softly came room would impossible buy pr...      1   \n",
       "\n",
       "                                              SPAN_1 SPAN_2  \\\n",
       "0  idea space traveler visiting earth learn new d...   None   \n",
       "1  raised dignity godhead accidental death causin...   None   \n",
       "2  got one right thought drop over sort break ice...   None   \n",
       "3  want sign paper joshua lee gorman held pen pus...   None   \n",
       "4  reason love instinct different men earth born ...   None   \n",
       "5  incoherent word alluded specifically charles c...   None   \n",
       "6  must something left atlatl lance shot u looked...   None   \n",
       "7  tell run thing get want reached slowly forward...   None   \n",
       "8  happy nora merry always kind home nothing play...   None   \n",
       "9  spoke softly came room would impossible buy pr...   None   \n",
       "\n",
       "                                    TOKENIZED_SPAN_1  \n",
       "0  [idea, space, traveler, visiting, earth, learn...  \n",
       "1  [raised, dignity, god, accidental, death, caus...  \n",
       "2  [got, one, right, thought, drop, over, sort, b...  \n",
       "3  [want, sign, paper, joshua, lee, gorman, held,...  \n",
       "4  [reason, love, instinct, different, men, earth...  \n",
       "5  [inc, word, all, specifically, charles, course...  \n",
       "6  [must, something, left, at, lance, shot, u, lo...  \n",
       "7  [tell, run, thing, get, want, reached, slowly,...  \n",
       "8  [happy, nora, merry, always, kind, home, nothi...  \n",
       "9  [spoke, softly, came, room, would, impossible,...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The idea of space travelers visiting earth to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"He whom we raised to the dignity of godhead o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"I've got one right here. Thought I'd drop ove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"I want you to sign these papers, Joshua.\" Lee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Is that reason why we should not love?\" \"No. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1596</td>\n",
       "      <td>Held prisoner with Joan, top of Robbins Buildi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1597</td>\n",
       "      <td>What Ramsey had done was as clear to him now a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1598</td>\n",
       "      <td>“Yes, indeed, what has happened?” exclaimed Eu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1599</td>\n",
       "      <td>Are you all right, darling? Did I forget anyth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1999</td>\n",
       "      <td>I don't follow him at all. His theory's probab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1601 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               TEXT  LABEL\n",
       "0        0  The idea of space travelers visiting earth to ...      0\n",
       "1        1  \"He whom we raised to the dignity of godhead o...      0\n",
       "2        2  \"I've got one right here. Thought I'd drop ove...      1\n",
       "3        3  \"I want you to sign these papers, Joshua.\" Lee...      1\n",
       "4        4  \"Is that reason why we should not love?\" \"No. ...      1\n",
       "...    ...                                                ...    ...\n",
       "1596  1596  Held prisoner with Joan, top of Robbins Buildi...      0\n",
       "1597  1597  What Ramsey had done was as clear to him now a...      0\n",
       "1598  1598  “Yes, indeed, what has happened?” exclaimed Eu...      0\n",
       "1599  1599  Are you all right, darling? Did I forget anyth...      1\n",
       "1600  1999  I don't follow him at all. His theory's probab...      0\n",
       "\n",
       "[1601 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
